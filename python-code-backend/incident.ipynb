{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from datetime import datetime\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "REPORTS_PAGE_URL = \"https://www.dgca.gov.in/digigov-portal/?baseLocale=hi?dynamicPage=IncidentReports/500006/0/viewApplicationDtlsReq\"\n",
    "# Updated to match our folder structure\n",
    "DOWNLOAD_FOLDER = os.path.join(os.getcwd(), \"pdfs\", \"incident\")\n",
    "WAIT_TIMEOUT = 45\n",
    "MAX_RETRIES = 3\n",
    "# --- END OF CONFIGURATION ---\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('incident_scraper.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Setup Firefox driver with improved configuration\"\"\"\n",
    "    firefox_options = webdriver.FirefoxOptions()\n",
    "    \n",
    "    # Download preferences\n",
    "    firefox_options.set_preference(\"browser.download.folderList\", 2)\n",
    "    firefox_options.set_preference(\"browser.download.dir\", DOWNLOAD_FOLDER)\n",
    "    firefox_options.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/pdf,application/octet-stream\")\n",
    "    firefox_options.set_preference(\"pdfjs.disabled\", True)\n",
    "    firefox_options.set_preference(\"browser.download.useDownloadDir\", True)\n",
    "    \n",
    "    # Performance improvements\n",
    "    firefox_options.set_preference(\"network.http.pipelining\", True)\n",
    "    firefox_options.set_preference(\"network.http.proxy.pipelining\", True)\n",
    "    firefox_options.set_preference(\"network.http.pipelining.maxrequests\", 8)\n",
    "    firefox_options.set_preference(\"content.notify.interval\", 500000)\n",
    "    firefox_options.set_preference(\"content.notify.ontimer\", True)\n",
    "    firefox_options.set_preference(\"content.switch.threshold\", 250000)\n",
    "    \n",
    "    # Disable images and CSS for faster loading (optional)\n",
    "    # firefox_options.set_preference(\"permissions.default.image\", 2)\n",
    "    # firefox_options.set_preference(\"permissions.default.stylesheet\", 2)\n",
    "    \n",
    "    service = Service(GeckoDriverManager().install())\n",
    "    driver = webdriver.Firefox(service=service, options=firefox_options)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def wait_for_download(download_folder, files_before, timeout=120):\n",
    "    \"\"\"Wait for download to complete with better detection\"\"\"\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < timeout:\n",
    "        files_after = os.listdir(download_folder)\n",
    "        new_files = [f for f in files_after if f not in files_before]\n",
    "        \n",
    "        # Check for completed downloads (no .part or .tmp files)\n",
    "        completed_files = [f for f in new_files if not any(ext in f for ext in ['.part', '.tmp', '.crdownload'])]\n",
    "        \n",
    "        if completed_files:\n",
    "            return completed_files[0]\n",
    "        time.sleep(1)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def download_report(driver, link, report_index):\n",
    "    \"\"\"Download a single report with retry logic\"\"\"\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            files_before = os.listdir(DOWNLOAD_FOLDER)\n",
    "            \n",
    "            # Scroll element into view before clicking\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", link)\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            # Use JavaScript click for reliability\n",
    "            driver.execute_script(\"arguments[0].click();\", link)\n",
    "            \n",
    "            # Wait for download\n",
    "            downloaded_file = wait_for_download(DOWNLOAD_FOLDER, files_before)\n",
    "            \n",
    "            if downloaded_file:\n",
    "                logger.info(f\"âœ… Report #{report_index + 1} downloaded: {downloaded_file}\")\n",
    "                return True\n",
    "            else:\n",
    "                logger.warning(f\"âŒ Download timeout for report #{report_index + 1}, attempt {attempt + 1}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Error downloading report #{report_index + 1}, attempt {attempt + 1}: {e}\")\n",
    "            \n",
    "        if attempt < MAX_RETRIES - 1:\n",
    "            time.sleep(2)  # Wait before retry\n",
    "    \n",
    "    logger.error(f\"âŒ Failed to download report #{report_index + 1} after {MAX_RETRIES} attempts\")\n",
    "    return False\n",
    "\n",
    "def main():\n",
    "    start_time = datetime.now()\n",
    "    logger.info(\"ðŸš€ Starting DGCA Incident Reports Downloader...\")\n",
    "\n",
    "    # Create download directory\n",
    "    if not os.path.exists(DOWNLOAD_FOLDER):\n",
    "        os.makedirs(DOWNLOAD_FOLDER)\n",
    "        logger.info(f\"Created download folder: {DOWNLOAD_FOLDER}\")\n",
    "\n",
    "    driver = setup_driver()\n",
    "    wait = WebDriverWait(driver, WAIT_TIMEOUT)\n",
    "    \n",
    "    total_downloaded = 0\n",
    "    total_failed = 0\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"Navigating to: {REPORTS_PAGE_URL}\")\n",
    "        driver.get(REPORTS_PAGE_URL)\n",
    "\n",
    "        current_page = 1\n",
    "        while True:\n",
    "            logger.info(f\"\\nðŸ“„ Processing Page {current_page}...\")\n",
    "            \n",
    "            try:\n",
    "                # Wait for reports table to load\n",
    "                wait.until(EC.visibility_of_element_located((By.XPATH, \"//tbody/tr/td/a\")))\n",
    "                \n",
    "                # Get all report links on current page\n",
    "                report_links = driver.find_elements(By.XPATH, \"//tbody/tr/td/a\")\n",
    "                logger.info(f\"Found {len(report_links)} reports on page {current_page}\")\n",
    "\n",
    "                # Download each report\n",
    "                for index, link in enumerate(report_links):\n",
    "                    logger.info(f\"Processing report #{index + 1} on page {current_page}...\")\n",
    "                    \n",
    "                    if download_report(driver, link, index):\n",
    "                        total_downloaded += 1\n",
    "                    else:\n",
    "                        total_failed += 1\n",
    "                    \n",
    "                    # Small delay between downloads\n",
    "                    time.sleep(1)\n",
    "\n",
    "                # Try to go to next page\n",
    "                logger.info(\"Looking for next page...\")\n",
    "                try:\n",
    "                    next_page_number = current_page + 1\n",
    "                    next_page_link = wait.until(EC.element_to_be_clickable(\n",
    "                        (By.XPATH, f\"//a[contains(@class, 'paginate_button') and text()='{next_page_number}']\")\n",
    "                    ))\n",
    "                    \n",
    "                    logger.info(f\"Clicking page {next_page_number}...\")\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_page_link)\n",
    "                    current_page += 1\n",
    "                    time.sleep(3)  # Wait for page to load\n",
    "                    \n",
    "                except (TimeoutException, NoSuchElementException):\n",
    "                    logger.info(\"No more pages found. Scraping complete!\")\n",
    "                    break\n",
    "                    \n",
    "            except TimeoutException:\n",
    "                logger.error(f\"Timeout waiting for page {current_page} to load\")\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Script-level error: {e}\")\n",
    "    finally:\n",
    "        end_time = datetime.now()\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        logger.info(f\"\\nðŸ“Š SCRAPING SUMMARY:\")\n",
    "        logger.info(f\"   Total pages processed: {current_page}\")\n",
    "        logger.info(f\"   Successfully downloaded: {total_downloaded} reports\")\n",
    "        logger.info(f\"   Failed downloads: {total_failed} reports\")\n",
    "        logger.info(f\"   Duration: {duration}\")\n",
    "        logger.info(f\"   Files saved to: {DOWNLOAD_FOLDER}\")\n",
    "        \n",
    "        logger.info(\"Closing browser...\")\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
